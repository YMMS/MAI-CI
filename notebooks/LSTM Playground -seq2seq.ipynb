{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../SubRecommender/data/train_reddit_data.json','r') as data_file:    \n",
    "    reddit_data = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    n = max(1, n)\n",
    "    return (l[i:i+n] for i in range(0, len(l), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(reddit_data,columns=['user','subreddit','utc_stamp'])\n",
    "df['utc_stamp'] = pd.to_datetime(df['utc_stamp'],unit='s')\n",
    "df.sort_values(by=['user','utc_stamp'], ascending=True, inplace=True)\n",
    "users = list(df.groupby('user')['user'].nunique().keys())\n",
    "sub_list = list(df.groupby('subreddit')['subreddit'].nunique().keys())\n",
    "training_sequences = []\n",
    "training_labels = []\n",
    "seq_lengths = []\n",
    "for usr in users:\n",
    "    user_comment_subs = list(df.loc[df['user'] == usr]['subreddit'].values)\n",
    "    comment_chunks = chunks(user_comment_subs,25)\n",
    "    for chnk in comment_chunks:\n",
    "        label = sub_list.index(random.choice(chnk))\n",
    "        training_labels.append(label)\n",
    "        chnk_seq = [sub_list.index(sub) for sub in chnk if sub_list.index(sub) != label]\n",
    "        training_sequences.append(chnk_seq)  \n",
    "        seq_lengths.append(len(chnk_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_seq = ['techsupport', 'indie', 'funny', 'gameideas', 'pcmasterrace', 'skateboarding', 'skateboarding', 'skateboarding', 'skateboarding', 'CodAW', 'gaming', 'GrandTheftAutoV', 'trees', 'gaming', 'skateboarding', 'pcmasterrace', 'pcmasterrace', 'pcmasterrace', 'pcmasterrace', 'pcmasterrace', 'pcmasterrace', 'whatisthisthing', 'longboarding', 'pcmasterrace']\n",
      "training_label = pics\n"
     ]
    }
   ],
   "source": [
    "print('training_seq = ' + str(training_sequences[10]))\n",
    "print('training_label = ' + training_labels[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_length</th>\n",
       "      <th>sub_label</th>\n",
       "      <th>sub_seqs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>1623</td>\n",
       "      <td>[1298, 1297, 1298, 1298, 1298, 1298, 1298, 129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>4164</td>\n",
       "      <td>[3465, 4267, 1908, 2959, 1623, 1623]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4164</td>\n",
       "      <td>[1908, 3803, 3803]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>4164</td>\n",
       "      <td>[263, 263, 184, 184, 184, 852, 852, 1374, 1298...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4078</td>\n",
       "      <td>[4164, 4164, 852]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seq_length  sub_label                                           sub_seqs\n",
       "0          21       1623  [1298, 1297, 1298, 1298, 1298, 1298, 1298, 129...\n",
       "1           6       4164               [3465, 4267, 1908, 2959, 1623, 1623]\n",
       "2           3       4164                                 [1908, 3803, 3803]\n",
       "3          10       4164  [263, 263, 184, 184, 184, 852, 852, 1374, 1298...\n",
       "4           3       4078                                  [4164, 4164, 852]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame({'sub_seqs':training_sequences,'sub_label':training_labels,'seq_length':seq_lengths})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_len, test_len = np.floor(len(train_df)*0.8), np.floor(len(train_df)*0.2)\n",
    "train, test = train_df.ix[:train_len-1], train_df.ix[train_len:train_len + test_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = sub_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BucketedDataIterator():\n",
    "    def __init__(self, df, num_buckets = 5):\n",
    "        df = df.sort_values('seq_length').reset_index(drop=True)\n",
    "        self.size = len(df) / num_buckets\n",
    "        self.dfs = []\n",
    "        for bucket in range(num_buckets):\n",
    "            self.dfs.append(df.ix[bucket*self.size: (bucket+1)*self.size - 1])\n",
    "        self.num_buckets = num_buckets\n",
    "\n",
    "        # cursor[i] will be the cursor for the ith bucket\n",
    "        self.cursor = np.array([0] * num_buckets)\n",
    "        self.shuffle()\n",
    "\n",
    "        self.epochs = 0\n",
    "\n",
    "    def shuffle(self):\n",
    "        #sorts dataframe by sequence length, but keeps it random within the same length\n",
    "        for i in range(self.num_buckets):\n",
    "            self.dfs[i] = self.dfs[i].sample(frac=1).reset_index(drop=True)\n",
    "            self.cursor[i] = 0\n",
    "\n",
    "    def next_batch(self, n):\n",
    "        if np.any(self.cursor+n+1 > self.size):\n",
    "            self.epochs += 1\n",
    "            self.shuffle()\n",
    "\n",
    "        i = np.random.randint(0,self.num_buckets)\n",
    "\n",
    "        res = self.dfs[i].ix[self.cursor[i]:self.cursor[i]+n-1]\n",
    "        self.cursor[i] += n\n",
    "\n",
    "        # Pad sequences with 0s so they are all the same length\n",
    "        maxlen = max(res['seq_length'])\n",
    "        x = np.zeros([n, maxlen], dtype=np.int32)\n",
    "        for i, x_i in enumerate(x):\n",
    "            x_i[:res['seq_length'].values[i]] = res['sub_label'].values[i]\n",
    "\n",
    "        return x, res['sub_label'], res['seq_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reset_graph():\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "def build_graph(\n",
    "    vocab_size = len(vocab),\n",
    "    state_size = 64,\n",
    "    batch_size = 256,\n",
    "    num_classes = len(vocab)):\n",
    "\n",
    "    reset_graph()\n",
    "\n",
    "    # Placeholders\n",
    "    x = tf.placeholder(tf.int32, [batch_size, None]) # [batch_size, num_steps]\n",
    "    seqlen = tf.placeholder(tf.int32, [batch_size])\n",
    "    y = tf.placeholder(tf.int32, [batch_size])\n",
    "    keep_prob = tf.placeholder_with_default(1.0, [])\n",
    "\n",
    "    # Embedding layer\n",
    "    embeddings = tf.get_variable('embedding_matrix', [vocab_size, state_size])\n",
    "    rnn_inputs = tf.nn.embedding_lookup(embeddings, x)\n",
    "\n",
    "    # RNN\n",
    "    cell = tf.nn.rnn_cell.GRUCell(state_size)\n",
    "    init_state = tf.get_variable('init_state', [1, state_size],\n",
    "                                 initializer=tf.constant_initializer(0.0))\n",
    "    init_state = tf.tile(init_state, [batch_size, 1])\n",
    "    rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, sequence_length=seqlen,\n",
    "                                                 initial_state=init_state)\n",
    "\n",
    "    # Add dropout, as the model otherwise quickly overfits\n",
    "    rnn_outputs = tf.nn.dropout(rnn_outputs, keep_prob)\n",
    "\n",
    "    \"\"\"\n",
    "    Obtain the last relevant output. The best approach in the future will be to use:\n",
    "\n",
    "        last_rnn_output = tf.gather_nd(rnn_outputs, tf.pack([tf.range(batch_size), seqlen-1], axis=1))\n",
    "\n",
    "    which is the Tensorflow equivalent of numpy's rnn_outputs[range(30), seqlen-1, :], but the\n",
    "    gradient for this op has not been implemented as of this writing.\n",
    "\n",
    "    The below solution works, but throws a UserWarning re: the gradient.\n",
    "    \"\"\"\n",
    "    idx = tf.range(batch_size)*tf.shape(rnn_outputs)[1] + (seqlen - 1)\n",
    "    last_rnn_output = tf.gather(tf.reshape(rnn_outputs, [-1, state_size]), idx)\n",
    "\n",
    "    # Softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        W = tf.get_variable('W', [state_size, num_classes])\n",
    "        b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "    logits = tf.matmul(last_rnn_output, W) + b\n",
    "    preds = tf.nn.softmax(logits)\n",
    "    correct = tf.equal(tf.cast(tf.argmax(preds,1),tf.int32), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y))\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "    return {\n",
    "        'x': x,\n",
    "        'seqlen': seqlen,\n",
    "        'y': y,\n",
    "        'dropout': keep_prob,\n",
    "        'loss': loss,\n",
    "        'ts': train_step,\n",
    "        'preds': preds,\n",
    "        'accuracy': accuracy,\n",
    "        'saver': tf.train.Saver()\n",
    "    }\n",
    "\n",
    "def train_graph(graph, batch_size = 256, num_epochs = 10, iterator = PaddedDataIterator,save=False):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        tr = iterator(train)\n",
    "        te = iterator(test)\n",
    "\n",
    "        step, accuracy = 0, 0\n",
    "        tr_losses, te_losses = [], []\n",
    "        current_epoch = 0\n",
    "        while current_epoch < num_epochs:\n",
    "            step += 1\n",
    "            batch = tr.next_batch(batch_size)\n",
    "            feed = {g['x']: batch[0], g['y']: batch[1], g['seqlen']: batch[2], g['dropout']: 0.6}\n",
    "            accuracy_, _ = sess.run([g['accuracy'], g['ts']], feed_dict=feed)\n",
    "            accuracy += accuracy_\n",
    "\n",
    "            if tr.epochs > current_epoch:\n",
    "                current_epoch += 1\n",
    "                tr_losses.append(accuracy / step)\n",
    "                step, accuracy = 0, 0\n",
    "\n",
    "                #eval test set\n",
    "                te_epoch = te.epochs\n",
    "                while te.epochs == te_epoch:\n",
    "                    step += 1\n",
    "                    batch = te.next_batch(batch_size)\n",
    "                    feed = {g['x']: batch[0], g['y']: batch[1], g['seqlen']: batch[2]}\n",
    "                    accuracy_ = sess.run([g['accuracy']], feed_dict=feed)[0]\n",
    "                    accuracy += accuracy_\n",
    "\n",
    "                te_losses.append(accuracy / step)\n",
    "                step, accuracy = 0,0\n",
    "                print(\"Accuracy after epoch\", current_epoch, \" - tr:\", tr_losses[-1], \"- te:\", te_losses[-1])\n",
    "                \n",
    "        if isinstance(save, str):\n",
    "            g['saver'].save(sess, save)\n",
    "\n",
    "    return tr_losses, te_losses\n",
    "\n",
    "def recommend_subs(g, checkpoint,pred_data,batch_size):\n",
    "    te = BucketedDataIterator(pred_data,num_buckets=1)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        g['saver'].restore(sess, checkpoint)\n",
    "        batch = te.next_batch(batch_size)\n",
    "        feed = {g['x']: batch[0],g['y']: batch[1], g['seqlen']: batch[2]}\n",
    "        preds = sess.run([g['preds']], feed_dict=feed)[0]\n",
    "        return tf.cast(tf.argmax(preds,1),tf.int32).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2593 2593 2593 ..., 2593 2593    0]\n",
      " [4060 4060 4060 ..., 4060 4060    0]\n",
      " [3131 3131 3131 ..., 3131 3131    0]\n",
      " ..., \n",
      " [4151 4151 4151 ..., 4151 4151    0]\n",
      " [3697 3697 3697 ..., 3697    0    0]\n",
      " [2348 2348 2348 ..., 2348 2348    0]]\n",
      "[[ 690  690  690 ...,  690  690  690]\n",
      " [4078 4078 4078 ..., 4078 4078 4078]\n",
      " [4204 4204 4204 ..., 4204 4204 4204]\n",
      " ..., \n",
      " [3542 3542 3542 ..., 3542 3542 3542]\n",
      " [3733 3733 3733 ..., 3733 3733 3733]\n",
      " [1248 1248 1248 ..., 1248 1248 1248]]\n",
      "Accuracy after epoch 1  - tr: 0.000434027777778 - te: 0.001953125\n"
     ]
    }
   ],
   "source": [
    "g = build_graph()\n",
    "tr_losses, te_losses = train_graph(g,num_epochs=1,iterator=BucketedDataIterator,\n",
    "                                   save='../SubRecommender/models/seqtest10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_pred_data(pred_data,batch_size):\n",
    "    i = len(pred_data)\n",
    "    while i < batch_size:\n",
    "        pred_data.append([0])\n",
    "        i = i + 1\n",
    "    return pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_length</th>\n",
       "      <th>sub_label</th>\n",
       "      <th>sub_seqs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5886</th>\n",
       "      <td>7</td>\n",
       "      <td>4117</td>\n",
       "      <td>[3492, 273, 2930, 2930, 3019, 3492, 2930]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5887</th>\n",
       "      <td>19</td>\n",
       "      <td>4117</td>\n",
       "      <td>[2930, 2930, 273, 273, 1329, 2181, 3492, 2181,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5888</th>\n",
       "      <td>12</td>\n",
       "      <td>4117</td>\n",
       "      <td>[1329, 1329, 2181, 3492, 273, 2930, 3623, 3492...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5889</th>\n",
       "      <td>18</td>\n",
       "      <td>1329</td>\n",
       "      <td>[2181, 2181, 4117, 273, 3623, 3623, 2930, 2930...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5890</th>\n",
       "      <td>18</td>\n",
       "      <td>2930</td>\n",
       "      <td>[4117, 1329, 1329, 273, 3492, 3492, 4117, 4117...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      seq_length  sub_label                                           sub_seqs\n",
       "5886           7       4117          [3492, 273, 2930, 2930, 3019, 3492, 2930]\n",
       "5887          19       4117  [2930, 2930, 273, 273, 1329, 2181, 3492, 2181,...\n",
       "5888          12       4117  [1329, 1329, 2181, 3492, 273, 2930, 3623, 3492...\n",
       "5889          18       1329  [2181, 2181, 4117, 273, 3623, 3623, 2930, 2930...\n",
       "5890          18       2930  [4117, 1329, 1329, 273, 3492, 3492, 4117, 4117..."
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_seqs</th>\n",
       "      <th>sub_label</th>\n",
       "      <th>seq_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[18, 5, 40, 23, 1004, 34, 67, 1234]</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sub_seqs  sub_label  seq_length\n",
       "0  [18, 5, 40, 23, 1004, 34, 67, 1234]          0           8\n",
       "1                                  [0]          0           1\n",
       "2                                  [0]          0           1\n",
       "3                                  [0]          0           1\n",
       "4                                  [0]          0           1"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_preds = [[3492, 273, 2930, 2930, 3019, 3492, 2930]]\n",
    "pad_test_preds = pad_pred_data(test_preds,256)\n",
    "test_df = pd.DataFrame({'sub_seqs':pad_test_preds})\n",
    "test_df['sub_label'] = 0\n",
    "test_df['seq_length'] = test_df.apply (lambda row: len(row['sub_seqs']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1472, 24) for Tensor 'Placeholder:0', which has shape '(256, ?)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-268-1927f8ac03eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecommend_subs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'../SubRecommender/models/seqtest10'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-267-ec5186cc4bec>\u001b[0m in \u001b[0;36mrecommend_subs\u001b[0;34m(g, checkpoint, pred_data, batch_size)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mte\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mfeed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'seqlen'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'preds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    941\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    944\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1472, 24) for Tensor 'Placeholder:0', which has shape '(256, ?)'"
     ]
    }
   ],
   "source": [
    " recs = recommend_subs(g,'../SubRecommender/models/seqtest10',test,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  69, 2934,  285,  281,  390, 2972,  595,  556, 2972,  810,  583,\n",
       "       1454, 1247, 1748, 2614,   45, 4056,  868, 2055, 1160, 4421, 2386,\n",
       "       4428, 2977, 4083, 2355,  244, 4184, 2532, 4341,   52, 3950, 3510,\n",
       "       3246, 4341,  694, 2355,   68,  283, 2235, 1247, 4184, 3608,   45,\n",
       "       2582, 4202,  556, 3246, 3981,  586, 2972, 1748, 1418,  645,  707,\n",
       "         45,  691, 2575,  390, 1340,   45, 1411, 1204, 2934, 3977,  406,\n",
       "        406, 2905, 1216,  869, 2517,  583, 1204, 1482, 2165, 3849, 3372,\n",
       "       1656, 1313, 3588,  949, 4074, 2120, 2125, 1247, 2016, 3981, 4341,\n",
       "       1454, 1917, 1454, 1247,  543,   23,  544, 1160,  829,   45, 2488,\n",
       "       1313,  281,   45, 1382, 1809, 1160, 4074,  317, 3608, 2355, 2153,\n",
       "       1777,  548,  316, 4387,  390, 1092, 1247,   68,  784, 2407,   84,\n",
       "         49,  986,  113, 4341, 1160, 1809, 3977, 2403,  884,  502,   68,\n",
       "         68, 4341, 2355,   45, 4341, 4083, 4341,  869,   45, 1501,   68,\n",
       "       1313,  183,  185, 2456, 1204, 1302, 4341, 1247,  114, 2125,  281,\n",
       "       2403, 4341, 2447, 3305,  383,   23,   45,  869, 4147, 1204, 2977,\n",
       "       1454, 1204, 2517, 1497, 4428, 2934, 1948,  281,  909, 4083, 2355,\n",
       "       3154, 2125,   11,  447, 2488,   45, 3488, 3977, 3168, 1501, 2153,\n",
       "       4301, 3508, 2966, 2456,   45, 1247, 4341, 1541, 1313, 3128,   45,\n",
       "         45,  666, 4083, 4267, 2153, 1077, 3311, 4341,  133, 2188,  971,\n",
       "       1160,   45, 2488, 2151, 1979, 2863, 4267,  390, 1465,   45, 3608,\n",
       "         45, 1418, 1247, 2582, 1247,  390, 3915,  189, 3855,  447,  447,\n",
       "       1274, 2355,  645, 4218, 1828,   68,   85, 3588, 3350,  185, 2153,\n",
       "       1951, 4341, 1985, 1160, 1249, 4343, 3608,  517,  544, 3572,  548,\n",
       "        826, 1824, 2884])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
