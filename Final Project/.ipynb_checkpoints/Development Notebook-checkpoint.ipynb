{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import os\n",
    "import configparser\n",
    "import webbrowser\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "os.chdir(\"C:/Users/macle/Desktop/UPC Masters/Semester 2/CI/Final Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('secrets.ini')\n",
    "\n",
    "reddit_client_id = config.get('reddit', 'client_id')\n",
    "reddit_api_key = config.get('reddit', 'api_key')\n",
    "r.set_oauth_app_info(client_id=reddit_client_id,\n",
    "                      client_secret=reddit_api_key,\n",
    "                      redirect_uri='http://cole-maclean.github.io/MAI-CI/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = r.get_authorize_url('uniqueKey', 'identity', True)\n",
    "webbrowser.open(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "access_information = r.get_access_information('B3w4W9k5xFbJpaLv8Xpuf-iQj34')\n",
    "r.set_access_credentials(**access_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upcmaici 1\n"
     ]
    }
   ],
   "source": [
    "authenticated_user = r.get_me()\n",
    "print(authenticated_user.name, authenticated_user.link_karma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapping 0th subreddit\n",
      "scrapping users from subreddit r/csgogambling\n",
      "scrapping 1th subreddit\n",
      "scrapping users from subreddit r/pcmasterrace\n",
      "scrapping 2th subreddit\n",
      "scrapping users from subreddit r/politics\n",
      "scrapping data for user AutoModerator\n",
      "scrapping 3th subreddit\n",
      "scrapping users from subreddit r/OnOff"
     ]
    }
   ],
   "source": [
    "with open('reddit_data.json','r') as data_file:    \n",
    "    reddit_data = json.load(data_file)\n",
    "with open('scrapped_users.json','r') as data_file:    \n",
    "    scrapped_users = json.load(data_file)\n",
    "for i in range(10):\n",
    "    print (\"scrapping \" + str(i) + \"th subreddit\")\n",
    "    rand_submission = r.get_random_submission()\n",
    "    print (\"scrapping users from subreddit r/\" + rand_submission.subreddit.display_name)\n",
    "    if len(rand_submission.comments) >=3:\n",
    "        rnd_comments = random.sample(rand_submission.comments,min(10,len(rand_submission.comments)))\n",
    "        for comment in rnd_comments:\n",
    "            if isinstance(comment, praw.objects.Comment):\n",
    "                user = comment.author\n",
    "                if user:\n",
    "                    print (\"scrapping data for user \" + user.name)\n",
    "                    if user.name in scrapped_users:\n",
    "                        print ('user ' + user.name + 'already scraped')\n",
    "                    else:\n",
    "                        scrapped_users.append(user.name)\n",
    "                        for user_comment in user.get_comments(limit=None,_use_oauth=False):\n",
    "                            body = user_comment.body.split()\n",
    "                            if len(body) >= 10:\n",
    "                                rand_words = random.sample(body,10)\n",
    "                            else:\n",
    "                                rand_words = body\n",
    "                            reddit_data.append([user_comment.subreddit.display_name,\n",
    "                                                                              user_comment.created_utc,rand_words])\n",
    "                    \n",
    "with open('reddit_data.json','w') as data_file:\n",
    "    json.dump(reddit_data, data_file)\n",
    "with open('scrapped_users.json','w') as data_file:\n",
    "    json.dump(scrapped_users, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_subreddits = []\n",
    "list_of_words = []\n",
    "for key,data in reddit_data.items():\n",
    "    for user_comment in data:\n",
    "        all_subreddits.append(user_comment[0])\n",
    "        for word in user_comment[2]:\n",
    "            list_of_words.append(word)\n",
    "subs = set(all_subreddits)\n",
    "bag_of_words = set(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_data.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
