{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import os\n",
    "import configparser\n",
    "import webbrowser\n",
    "import random\n",
    "import json\n",
    "os.chdir(\"C:/Users/macle/Desktop/UPC Masters/Semester 2/CI/Final Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('secrets.ini')\n",
    "\n",
    "reddit_client_id = config.get('reddit', 'client_id')\n",
    "reddit_api_key = config.get('reddit', 'api_key')\n",
    "r.set_oauth_app_info(client_id=reddit_client_id,\n",
    "                      client_secret=reddit_api_key,\n",
    "                      redirect_uri='http://cole-maclean.github.io/MAI-CI/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = r.get_authorize_url('uniqueKey', 'identity', True)\n",
    "webbrowser.open(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "access_information = r.get_access_information('Er_MOGdgrVmno26aHV4lU-kg530')\n",
    "r.set_access_credentials(**access_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upcmaici 1\n"
     ]
    }
   ],
   "source": [
    "authenticated_user = r.get_me()\n",
    "print(authenticated_user.name, authenticated_user.link_karma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapping subreddit r/AskReddit\n",
      "scrapping data for user OvyZ\n",
      "scrapping data for user sligathor\n",
      "scrapping data for user nolongeralurker159\n",
      "scrapping data for user Threwthelookinglass\n",
      "scrapping data for user pm_me_ur_grandad\n",
      "scrapping data for user happygilmomyGOD\n",
      "scrapping data for user Donzafetus\n",
      "scrapping data for user xanthraxoid\n",
      "scrapping data for user _Skylake_\n",
      "scrapping data for user BackhandinFools\n",
      "scrapping subreddit r/TrueAnnaSophiaRobb\n",
      "scrapping subreddit r/AskReddit\n",
      "scrapping subreddit r/AutoNewspaper\n",
      "scrapping subreddit r/nba\n",
      "scrapping data for user qa2\n",
      "scrapping data for user JesseJaymz\n",
      "scrapping data for user BlindManBaldwin\n",
      "scrapping data for user BatmanNoPrep\n",
      "scrapping data for user GilsWorld\n",
      "scrapping data for user exasperated_dreams\n",
      "scrapping data for user turddit\n",
      "scrapping data for user alexredekop\n",
      "scrapping data for user Streg\n",
      "scrapping data for user twotonkatrucks\n",
      "scrapping subreddit r/FIFA\n",
      "scrapping subreddit r/rapbattles"
     ]
    }
   ],
   "source": [
    "with open('reddit_data.json','r') as data_file:    \n",
    "    reddit_data = json.load(data_file)\n",
    "for i in range(10):\n",
    "    rand_submission = r.get_random_submission()\n",
    "    print (\"scrapping users from subreddit r/\" + rand_submission.subreddit.display_name)\n",
    "    if len(rand_submission.comments) >=10:\n",
    "        rnd_comments = random.sample(rand_submission.comments, 10)\n",
    "        for comment in rnd_comments:\n",
    "            if isinstance(comment, praw.objects.Comment)\n",
    "                user = comment.author\n",
    "                if user.name:\n",
    "                    print (\"scrapping data for user \" + user.name)\n",
    "                    if user.name in reddit_data.keys():\n",
    "                        print ('user ' + user.name + 'already scraped')\n",
    "                    else:\n",
    "                        for user_comment in user.get_comments(limit=None,_use_oauth=False):\n",
    "                            body = user_comment.body.split()\n",
    "                            if len(body) >= 10:\n",
    "                                rand_words = random.sample(body,10)\n",
    "                            else:\n",
    "                                rand_words = body\n",
    "                            if user_comment.author.name in reddit_data.keys():\n",
    "                                reddit_data[user_comment.author.name].append([user_comment.subreddit.display_name,\n",
    "                                                                              user_comment.created_utc,rand_words])\n",
    "                            else:\n",
    "                                reddit_data[user_comment.author.name] = [[user_comment.subreddit.display_name,\n",
    "                                                                          user_comment.created_utc,rand_words]]\n",
    "with open('reddit_data.json','w') as data_file:\n",
    "    json.dump(reddit_data, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['EpicalaxyMaster', 'themiragechild', 'Zachstradamus', 'housevulture', 'LinkoftheCentury', 'ZoomBoingDing', 'voidhearts', 'herefortheturnips', 'iEuphemia', 'Neatfreax', 'Megzasaurusrex'])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subreddits = []\n",
    "list_of_words = []\n",
    "for key,data in reddit_data.items():\n",
    "    for user_comment in data:\n",
    "        all_subreddits.append(user_comment[0])\n",
    "        for word in user_comment[2]:\n",
    "            list_of_words.append(word)\n",
    "subs = set(all_subreddits)\n",
    "bag_of_words = set(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(next(bag_of_words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
